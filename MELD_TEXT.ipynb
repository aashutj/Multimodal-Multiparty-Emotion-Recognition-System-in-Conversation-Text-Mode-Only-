{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MELD_TEXT.ipynb","provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyOGHgbhqZZQ+UNsl6h4uTEg"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"tcp_SUmPS9uS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"status":"ok","timestamp":1593886003343,"user_tz":-330,"elapsed":26870,"user":{"displayName":"Ashutosh Jindal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5QBA10uYxcnUyu5IeQy9b1yLimJ-Fm5utDrv3=s64","userId":"00737864440241259346"}},"outputId":"153366d5-b62b-4d5d-fdbd-9fb1a38fd8ba"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jEulwfVKwWOQ","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593886011390,"user_tz":-330,"elapsed":3545,"user":{"displayName":"Ashutosh Jindal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5QBA10uYxcnUyu5IeQy9b1yLimJ-Fm5utDrv3=s64","userId":"00737864440241259346"}},"outputId":"b8b1b917-c679-4c9b-8560-3547bdd8c81b"},"source":["import argparse\n","from keras.layers import Input, Dense, Embedding, Conv2D, MaxPool2D, Lambda, LSTM, TimeDistributed, Masking, Bidirectional\n","from keras.layers import Reshape, Flatten, Dropout, Concatenate\n","from keras.callbacks import ModelCheckpoint, EarlyStopping\n","from keras.optimizers import Adam\n","from keras.models import Model, load_model\n","import keras.backend as K\n","from sklearn.model_selection import train_test_split#\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_recall_fscore_support\n","from sklearn.metrics import accuracy_score\n","import os, pickle, sys\n","import numpy as np\n","from collections import Counter, defaultdict\n","import pandas as pd"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"ySVLWN2o3A9r","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593886037142,"user_tz":-330,"elapsed":1233,"user":{"displayName":"Ashutosh Jindal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5QBA10uYxcnUyu5IeQy9b1yLimJ-Fm5utDrv3=s64","userId":"00737864440241259346"}}},"source":["max_length=50 \n","\n","class Dataloader:\n","    \n","    def __init__(self, mode=None):\n","\n","        try:\n","            assert(mode is not None)\n","        except AssertionError as e:\n","            print(\"Set mode as 'Sentiment''Emotion'\")\n","            exit()\n","\n","        self.MODE = mode \n","        self.max_l = max_length\n","\n","        x = pickle.load(open(\"/content/drive/My Drive/MELD-master/data/pickles/data_{}.p\".format(self.MODE.lower()),\"rb\"))\n","        revs, self.W, self.word_idx_map, self.vocab, _, label_index = x[0], x[1], x[2], x[3], x[4], x[5]\n","        self.num_classes = len(label_index)\n","        print(\"Labels used for this classification: \", label_index)\n","\n","\n","        \n","        self.train_data, self.val_data, self.test_data = {},{},{}\n","        for i in range(len(revs)):\n","            \n","            utterance_id = revs[i]['dialog']+\"_\"+revs[i]['utterance']\n","            sentence_word_indices = self.get_word_indices(revs[i]['text'])\n","            label = label_index[revs[i]['y']]\n","\n","            if revs[i]['split']==\"train\":\n","                self.train_data[utterance_id]=(sentence_word_indices,label)\n","            elif revs[i]['split']==\"val\":\n","                self.val_data[utterance_id]=(sentence_word_indices,label)\n","            elif revs[i]['split']==\"test\":\n","                self.test_data[utterance_id]=(sentence_word_indices,label)\n","\n","\n","       \n","        self.train_dialogue_ids = self.get_dialogue_ids(self.train_data.keys())\n","        self.val_dialogue_ids = self.get_dialogue_ids(self.val_data.keys())\n","        self.test_dialogue_ids = self.get_dialogue_ids(self.test_data.keys())\n","\n","        \n","        self.max_utts = self.get_max_utts(self.train_dialogue_ids, self.val_dialogue_ids, self.test_dialogue_ids)\n","\n","\n","    def get_word_indices(self, data_x):\n","        length = len(data_x.split())\n","        return np.array([self.word_idx_map[word] for word in data_x.split()] + [0]*(self.max_l-length))[:self.max_l]\n","\n","    def get_dialogue_ids(self, keys):\n","        ids=defaultdict(list)\n","        for key in keys:\n","            ids[key.split(\"_\")[0]].append(int(key.split(\"_\")[1]))\n","        for ID, utts in ids.items():\n","            ids[ID]=[str(utt) for utt in sorted(utts)]\n","        return ids\n","\n","    def get_max_utts(self, train_ids, val_ids, test_ids):\n","        max_utts_train = max([len(train_ids[vid]) for vid in train_ids.keys()])\n","        max_utts_val = max([len(val_ids[vid]) for vid in val_ids.keys()])\n","        max_utts_test = max([len(test_ids[vid]) for vid in test_ids.keys()])\n","        return np.max([max_utts_train, max_utts_val, max_utts_test])\n","\n","    def get_one_hot(self, label):\n","        label_arr = [0]*self.num_classes\n","        label_arr[label]=1\n","        return label_arr[:]\n","\n","\n","    def get_dialogue_text_embs(self):\n","        key = list(self.train_data.keys())[0]\n","        pad = [0]*len(self.train_data[key][0])\n","\n","        def get_emb(dialogue_id, local_data):\n","            dialogue_text = []\n","            for vid in dialogue_id.keys():\n","                local_text = []\n","                for utt in dialogue_id[vid]:\n","                    local_text.append(local_data[vid+\"_\"+str(utt)][0][:])\n","                for _ in range(self.max_utts-len(local_text)):\n","                    local_text.append(pad[:])\n","                dialogue_text.append(local_text[:self.max_utts])\n","            return np.array(dialogue_text)\n","\n","        self.train_dialogue_features = get_emb(self.train_dialogue_ids, self.train_data)\n","        self.val_dialogue_features = get_emb(self.val_dialogue_ids, self.val_data)\n","        self.test_dialogue_features = get_emb(self.test_dialogue_ids, self.test_data)\n","\n","\n","    def get_dialogue_labels(self):\n","\n","        def get_labels(ids, data):\n","            dialogue_label=[]\n","\n","            for vid, utts in ids.items():\n","                local_labels=[]\n","                for utt in utts:\n","                    local_labels.append(self.get_one_hot(data[vid+\"_\"+str(utt)][1]))\n","                for _ in range(self.max_utts-len(local_labels)):\n","                    local_labels.append(self.get_one_hot(1)) # Dummy label\n","                dialogue_label.append(local_labels[:self.max_utts])\n","            return np.array(dialogue_label)\n","\n","        self.train_dialogue_label=get_labels(self.train_dialogue_ids, self.train_data)\n","        self.val_dialogue_label=get_labels(self.val_dialogue_ids, self.val_data)\n","        self.test_dialogue_label=get_labels(self.test_dialogue_ids, self.test_data)\n","\n","    def get_dialogue_lengths(self):\n","\n","        self.train_dialogue_length, self.val_dialogue_length, self.test_dialogue_length=[], [], []\n","        for vid, utts in self.train_dialogue_ids.items():\n","            self.train_dialogue_length.append(len(utts))\n","        for vid, utts in self.val_dialogue_ids.items():\n","            self.val_dialogue_length.append(len(utts))\n","        for vid, utts in self.test_dialogue_ids.items():\n","            self.test_dialogue_length.append(len(utts))\n","\n","    def get_masks(self):\n","\n","        self.train_mask = np.zeros((len(self.train_dialogue_length), self.max_utts), dtype='float')\n","        for i in range(len(self.train_dialogue_length)):\n","            self.train_mask[i,:self.train_dialogue_length[i]]=1.0\n","        self.val_mask = np.zeros((len(self.val_dialogue_length), self.max_utts), dtype='float')\n","        for i in range(len(self.val_dialogue_length)):\n","            self.val_mask[i,:self.val_dialogue_length[i]]=1.0\n","        self.test_mask = np.zeros((len(self.test_dialogue_length), self.max_utts), dtype='float')\n","        for i in range(len(self.test_dialogue_length)):\n","            self.test_mask[i,:self.test_dialogue_length[i]]=1.0\n","\n","\n","    def load_text_data(self, ):\n","\n","        self.get_dialogue_text_embs()\n","        self.get_dialogue_lengths()\n","        self.get_dialogue_labels()\n","        self.get_masks()\n","\n","\n","    "],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"9kI9AY7V2pvq","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1593886043318,"user_tz":-330,"elapsed":1444,"user":{"displayName":"Ashutosh Jindal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5QBA10uYxcnUyu5IeQy9b1yLimJ-Fm5utDrv3=s64","userId":"00737864440241259346"}}},"source":["class bc_LSTM:\n","\n","\tdef __init__(self, args):\n","\t\tself.classification_mode = args.classify\n","\t\tself.modality = args.modality\n","\t\tself.PATH = \"/content/drive/My Drive/MELD-master/data/models/{}_weights_{}.hdf5\".format(args.modality,self.classification_mode.lower())\n","\t\tself.OUTPUT_PATH = \"/content/drive/My Drive/MELD-master/data/pickles/{}_{}.pkl\".format(args.modality,self.classification_mode.lower())\n","\t\tprint(\"Model initiated for {} classification\".format(self.classification_mode))\n","\n","\n","\tdef load_data(self,):\n","\n","\t\tprint('Loading data')\n","\t\tself.data = Dataloader(mode = self.classification_mode)\n","\n","\t\tself.data.load_text_data()\n","\n","\t\tself.train_x = self.data.train_dialogue_features\n","\t\tself.val_x = self.data.val_dialogue_features\n","\t\tself.test_x = self.data.test_dialogue_features\n","\n","\t\tself.train_y = self.data.train_dialogue_label\n","\t\tself.val_y = self.data.val_dialogue_label\n","\t\tself.test_y = self.data.test_dialogue_label\n","\n","\t\tself.train_mask = self.data.train_mask\n","\t\tself.val_mask = self.data.val_mask\n","\t\tself.test_mask = self.data.test_mask\n","\n","\t\tself.train_id = self.data.train_dialogue_ids.keys()\n","\t\tself.val_id = self.data.val_dialogue_ids.keys()\n","\t\tself.test_id = self.data.test_dialogue_ids.keys()\n","\n","\t\tself.sequence_length = self.train_x.shape[1]\n","\t\t\n","\t\tself.classes = self.train_y.shape[2]\n","\t\t\t\n","\n","\n","\tdef calc_test_result(self, pred_label, test_label, test_mask):\n","\n","\t\ttrue_label=[]\n","\t\tpredicted_label=[]\n","\n","\t\tfor i in range(pred_label.shape[0]):\n","\t\t\tfor j in range(pred_label.shape[1]):\n","\t\t\t\tif test_mask[i,j]==1:\n","\t\t\t\t\ttrue_label.append(np.argmax(test_label[i,j] ))\n","\t\t\t\t\tpredicted_label.append(np.argmax(pred_label[i,j] ))\n","\t\tprint(\"Confusion Matrix :\")\n","\t\tprint(confusion_matrix(true_label, predicted_label))\n","\t\tprint(\"Classification Report :\")\n","\t\tprint(classification_report(true_label, predicted_label, digits=4))\n","\t\tprint('Weighted FScore: \\n ', precision_recall_fscore_support(true_label, predicted_label, average='weighted'))\n","\n","\n","\tdef get_text_model(self):\n","\n","\t\t# Modality specific hyperparameters\n","\t\tself.epochs = 100\n","\t\tself.batch_size = 50\n","\n","\t\t# Modality specific parameters\n","\t\tself.embedding_dim = self.data.W.shape[1]\n","\n","\t\tself.vocabulary_size = self.data.W.shape[0]\n","\t\tself.filter_sizes = [3,4,5]\n","\t\tself.num_filters = 512\n","\n","\n","\t\tprint(\"Creating Model...\")\n","\n","\t\tsentence_length = self.train_x.shape[2]\n","\n","\n","\t\tembedding = Embedding(input_dim=self.vocabulary_size, output_dim=self.embedding_dim, weights=[self.data.W], input_length=sentence_length, trainable=False)\n","\t\tconv_0 = Conv2D(self.num_filters, kernel_size=(self.filter_sizes[0], self.embedding_dim), padding='valid', kernel_initializer='normal', activation='relu')\n","\t\tconv_1 = Conv2D(self.num_filters, kernel_size=(self.filter_sizes[1], self.embedding_dim), padding='valid', kernel_initializer='normal', activation='relu')\n","\t\tconv_2 = Conv2D(self.num_filters, kernel_size=(self.filter_sizes[2], self.embedding_dim), padding='valid', kernel_initializer='normal', activation='relu')\n","\t\tmaxpool_0 = MaxPool2D(pool_size=(sentence_length - self.filter_sizes[0] + 1, 1), strides=(1,1), padding='valid')\n","\t\tmaxpool_1 = MaxPool2D(pool_size=(sentence_length - self.filter_sizes[1] + 1, 1), strides=(1,1), padding='valid')\n","\t\tmaxpool_2 = MaxPool2D(pool_size=(sentence_length - self.filter_sizes[2] + 1, 1), strides=(1,1), padding='valid')\n","\t\tdense_func = Dense(100, activation='tanh', name=\"dense\")\n","\t\tdense_final = Dense(units=self.classes, activation='softmax')\n","\t\treshape_func = Reshape((sentence_length, self.embedding_dim, 1))\n","\n","\t\tdef slicer(x, index):\n","\t\t\treturn x[:,K.constant(index, dtype='int32'),:]\n","\n","\t\tdef slicer_output_shape(input_shape):\n","\t\t    shape = list(input_shape)\n","\t\t    assert len(shape) == 3  # batch, seq_len, sent_len\n","\t\t    new_shape = (shape[0], shape[2])\n","\t\t    return new_shape\n","\n","\t\tdef reshaper(x):\n","\t\t\treturn K.expand_dims(x, axis=3)\n","\n","\t\tdef flattener(x):\n","\t\t\tx = K.reshape(x, [-1, x.shape[1]*x.shape[3]])\n","\t\t\treturn x\n","\n","\t\tdef flattener_output_shape(input_shape):\n","\t\t    shape = list(input_shape)\n","\t\t    new_shape = (shape[0], 3*shape[3])\n","\t\t    return new_shape\n","\n","\t\tinputs = Input(shape=(self.sequence_length, sentence_length), dtype='int32')\n","\t\tcnn_output = []\n","\t\tfor ind in range(self.sequence_length):\n","\t\t\t\n","\t\t\tlocal_input = Lambda(slicer, output_shape=slicer_output_shape, arguments={\"index\":ind})(inputs) # Batch, word_indices\n","\t\t\t\n","\t\t\t#cnn-sent\n","\t\t\temb_output = embedding(local_input)\n","\t\t\treshape = Lambda(reshaper)(emb_output)\n","\t\t\tconcatenated_tensor = Concatenate(axis=1)([maxpool_0(conv_0(reshape)), maxpool_1(conv_1(reshape)), maxpool_2(conv_2(reshape))])\n","\t\t\tflatten = Lambda(flattener, output_shape=flattener_output_shape,)(concatenated_tensor)\n","\t\t\tdense_output = dense_func(flatten)\n","\t\t\tdropout = Dropout(0.5)(dense_output)\n","\t\t\tcnn_output.append(dropout)\n","\n","\t\tdef stack(x):\n","\t\t\treturn K.stack(x, axis=1)\n","\t\tcnn_outputs = Lambda(stack)(cnn_output)\n","\n","\t\tmasked = Masking(mask_value =0)(cnn_outputs)\n","\t\tlstm = Bidirectional(LSTM(300, activation='relu', return_sequences = True, dropout=0.3))(masked)\n","\t\tlstm = Bidirectional(LSTM(300, activation='relu', return_sequences = True, dropout=0.3), name=\"utter\")(lstm)\n","\t\toutput = TimeDistributed(Dense(self.classes,activation='softmax'))(lstm)\n","\n","\t\tmodel = Model(inputs, output)\n","\t\treturn model\n","\n","\n","\n","\tdef train_model(self):\n","\n","\t\tcheckpoint = ModelCheckpoint(self.PATH, monitor='val_loss', verbose=1, save_best_only=True, mode='auto')\n","\n","\t\tif self.modality == \"text\":\n","\t\t\tmodel = self.get_text_model()\n","\t\t\tmodel.compile(optimizer='adadelta', loss='categorical_crossentropy', sample_weight_mode='temporal')\n","\t\t\n","\n","\t\tearly_stopping = EarlyStopping(monitor='val_loss', patience=10)\n","\t\tmodel.fit(self.train_x, self.train_y,\n","\t\t                epochs=self.epochs,\n","\t\t                batch_size=self.batch_size,\n","\t\t                sample_weight=self.train_mask,\n","\t\t                shuffle=True, \n","\t\t                callbacks=[early_stopping, checkpoint],\n","\t\t                validation_data=(self.val_x, self.val_y, self.val_mask))\n","\n","\t\tself.test_model()\n","\n","\n","\n","\tdef test_model(self):\n","\n","\t\tmodel = load_model(self.PATH)\n","\t\tintermediate_layer_model = Model(input=model.input, output=model.get_layer(\"utter\").output)\n","\n","\t\tintermediate_output_train = intermediate_layer_model.predict(self.train_x)\n","\t\tintermediate_output_val = intermediate_layer_model.predict(self.val_x)\n","\t\tintermediate_output_test = intermediate_layer_model.predict(self.test_x)\n","\n","\t\ttrain_emb, val_emb, test_emb = {}, {}, {}\n","\t\tfor idx, ID in enumerate(self.train_id):\n","\t\t    train_emb[ID] = intermediate_output_train[idx]\n","\t\tfor idx, ID in enumerate(self.val_id):\n","\t\t    val_emb[ID] = intermediate_output_val[idx]\n","\t\tfor idx, ID in enumerate(self.test_id):\n","\t\t    test_emb[ID] = intermediate_output_test[idx]\n","\t\tpickle.dump([train_emb, val_emb, test_emb], open(self.OUTPUT_PATH, \"wb\"))\n","\n","\t\tself.calc_test_result(model.predict(self.test_x), self.test_y, self.test_mask)\n","\t\t"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"tlEeRTpo24gg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1593886052108,"user_tz":-330,"elapsed":2636,"user":{"displayName":"Ashutosh Jindal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5QBA10uYxcnUyu5IeQy9b1yLimJ-Fm5utDrv3=s64","userId":"00737864440241259346"}},"outputId":"24fe0ef3-c6ae-4655-e2a0-2daee16fd11d"},"source":["if __name__ == \"__main__\":\n","\n","\t\n","\tparser = argparse.ArgumentParser()\n","\tparser.required=True\n","\tparser.add_argument(\"-classify\", help=\"Set the classifiction to be 'Emotion' or 'Sentiment'\", required=True)\n","\tparser.add_argument(\"-modality\", help=\"Set the modality to be 'text' or 'audio' or 'bimodal'\", required=True)\n","\n","\targs = parser.parse_args(args=['-classify', 'Emotion', '-modality', 'text'])\n","\n","\t\n","\n","\targs.classify = args.classify.title()\n","\targs.modality = args.modality.lower()\n","\t\n","\t\n","\tfor directory in [\"/content/drive/My Drive/MELD-master/data/pickles\", \"/content/drive/My Drive/MELD-master/data/models\"]:\n","\t\tif not os.path.exists(directory):\n","\t\t    os.makedirs(directory)\n","\n","\n","\tmodel = bc_LSTM(args)\n","\tmodel.load_data()\n"," \n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Model initiated for Emotion classification\n","Loading data\n","Labels used for this classification:  {'neutral': 0, 'surprise': 1, 'fear': 2, 'sadness': 3, 'joy': 4, 'disgust': 5, 'anger': 6}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0WZyyOX6672F","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593876096819,"user_tz":-330,"elapsed":3801620,"user":{"displayName":"Ashutosh Jindal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5QBA10uYxcnUyu5IeQy9b1yLimJ-Fm5utDrv3=s64","userId":"00737864440241259346"}},"outputId":"4478f8cf-d5bf-4e92-fb82-e8cfbe48d37d"},"source":["model.train_model()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Creating Model...\n","Train on 1038 samples, validate on 114 samples\n","Epoch 1/100\n","1038/1038 [==============================] - 264s 254ms/step - loss: 0.4743 - val_loss: 0.4881\n","\n","Epoch 00001: val_loss improved from inf to 0.48811, saving model to /content/drive/My Drive/MELD-master/data/models/text_weights_emotion.hdf5\n","Epoch 2/100\n","1038/1038 [==============================] - 259s 249ms/step - loss: 0.4598 - val_loss: 0.4843\n","\n","Epoch 00002: val_loss improved from 0.48811 to 0.48430, saving model to /content/drive/My Drive/MELD-master/data/models/text_weights_emotion.hdf5\n","Epoch 3/100\n","1038/1038 [==============================] - 259s 250ms/step - loss: 0.4570 - val_loss: 0.4831\n","\n","Epoch 00003: val_loss improved from 0.48430 to 0.48306, saving model to /content/drive/My Drive/MELD-master/data/models/text_weights_emotion.hdf5\n","Epoch 4/100\n","1038/1038 [==============================] - 260s 250ms/step - loss: 0.4542 - val_loss: 0.4797\n","\n","Epoch 00004: val_loss improved from 0.48306 to 0.47972, saving model to /content/drive/My Drive/MELD-master/data/models/text_weights_emotion.hdf5\n","Epoch 5/100\n","1038/1038 [==============================] - 260s 251ms/step - loss: 0.4528 - val_loss: 0.4784\n","\n","Epoch 00005: val_loss improved from 0.47972 to 0.47836, saving model to /content/drive/My Drive/MELD-master/data/models/text_weights_emotion.hdf5\n","Epoch 6/100\n","1038/1038 [==============================] - 260s 251ms/step - loss: 0.4518 - val_loss: 0.4770\n","\n","Epoch 00006: val_loss improved from 0.47836 to 0.47695, saving model to /content/drive/My Drive/MELD-master/data/models/text_weights_emotion.hdf5\n","Epoch 7/100\n","1038/1038 [==============================] - 260s 251ms/step - loss: 0.4489 - val_loss: 0.4773\n","\n","Epoch 00007: val_loss did not improve from 0.47695\n","Epoch 8/100\n","1038/1038 [==============================] - 260s 250ms/step - loss: 0.4485 - val_loss: 0.4741\n","\n","Epoch 00008: val_loss improved from 0.47695 to 0.47415, saving model to /content/drive/My Drive/MELD-master/data/models/text_weights_emotion.hdf5\n","Epoch 9/100\n","1038/1038 [==============================] - 260s 250ms/step - loss: 0.4467 - val_loss: 0.4727\n","\n","Epoch 00009: val_loss improved from 0.47415 to 0.47267, saving model to /content/drive/My Drive/MELD-master/data/models/text_weights_emotion.hdf5\n","Epoch 10/100\n","1038/1038 [==============================] - 264s 254ms/step - loss: 0.4422 - val_loss: 0.4694\n","\n","Epoch 00010: val_loss improved from 0.47267 to 0.46942, saving model to /content/drive/My Drive/MELD-master/data/models/text_weights_emotion.hdf5\n","Epoch 11/100\n","1038/1038 [==============================] - 260s 250ms/step - loss: 0.4421 - val_loss: 0.4695\n","\n","Epoch 00011: val_loss did not improve from 0.46942\n","Epoch 12/100\n","1038/1038 [==============================] - 259s 250ms/step - loss: 0.4382 - val_loss: 0.4806\n","\n","Epoch 00012: val_loss did not improve from 0.46942\n","Epoch 13/100\n","1038/1038 [==============================] - 260s 250ms/step - loss: 0.4329 - val_loss: 0.4802\n","\n","Epoch 00013: val_loss did not improve from 0.46942\n","Epoch 14/100\n","1038/1038 [==============================] - 260s 250ms/step - loss: 0.4349 - val_loss: 0.4622\n","\n","Epoch 00014: val_loss improved from 0.46942 to 0.46216, saving model to /content/drive/My Drive/MELD-master/data/models/text_weights_emotion.hdf5\n","Epoch 15/100\n","1038/1038 [==============================] - 264s 254ms/step - loss: 0.4238 - val_loss: 0.4568\n","\n","Epoch 00015: val_loss improved from 0.46216 to 0.45685, saving model to /content/drive/My Drive/MELD-master/data/models/text_weights_emotion.hdf5\n","Epoch 16/100\n","1038/1038 [==============================] - 262s 252ms/step - loss: 0.4172 - val_loss: 0.4572\n","\n","Epoch 00016: val_loss did not improve from 0.45685\n","Epoch 17/100\n","1038/1038 [==============================] - 262s 252ms/step - loss: 0.4154 - val_loss: 0.4401\n","\n","Epoch 00017: val_loss improved from 0.45685 to 0.44009, saving model to /content/drive/My Drive/MELD-master/data/models/text_weights_emotion.hdf5\n","Epoch 18/100\n","1038/1038 [==============================] - 261s 252ms/step - loss: 0.4062 - val_loss: 0.4302\n","\n","Epoch 00018: val_loss improved from 0.44009 to 0.43023, saving model to /content/drive/My Drive/MELD-master/data/models/text_weights_emotion.hdf5\n","Epoch 19/100\n","1038/1038 [==============================] - 262s 252ms/step - loss: 0.4027 - val_loss: 0.4448\n","\n","Epoch 00019: val_loss did not improve from 0.43023\n","Epoch 20/100\n","1038/1038 [==============================] - 265s 256ms/step - loss: 0.3975 - val_loss: 0.4381\n","\n","Epoch 00020: val_loss did not improve from 0.43023\n","Epoch 21/100\n","1038/1038 [==============================] - 261s 251ms/step - loss: 0.3989 - val_loss: 0.4287\n","\n","Epoch 00021: val_loss improved from 0.43023 to 0.42873, saving model to /content/drive/My Drive/MELD-master/data/models/text_weights_emotion.hdf5\n","Epoch 22/100\n","1038/1038 [==============================] - 262s 252ms/step - loss: 0.3960 - val_loss: 0.4475\n","\n","Epoch 00022: val_loss did not improve from 0.42873\n","Epoch 23/100\n","1038/1038 [==============================] - 263s 254ms/step - loss: 0.3947 - val_loss: 0.4230\n","\n","Epoch 00023: val_loss improved from 0.42873 to 0.42304, saving model to /content/drive/My Drive/MELD-master/data/models/text_weights_emotion.hdf5\n","Epoch 24/100\n","1038/1038 [==============================] - 263s 253ms/step - loss: 0.3901 - val_loss: 0.4451\n","\n","Epoch 00024: val_loss did not improve from 0.42304\n","Epoch 25/100\n","1038/1038 [==============================] - 261s 252ms/step - loss: 0.3907 - val_loss: 0.4241\n","\n","Epoch 00025: val_loss did not improve from 0.42304\n","Epoch 26/100\n","1038/1038 [==============================] - 265s 256ms/step - loss: 0.3849 - val_loss: 0.4219\n","\n","Epoch 00026: val_loss improved from 0.42304 to 0.42193, saving model to /content/drive/My Drive/MELD-master/data/models/text_weights_emotion.hdf5\n","Epoch 27/100\n","1038/1038 [==============================] - 261s 252ms/step - loss: 0.3866 - val_loss: 0.4486\n","\n","Epoch 00027: val_loss did not improve from 0.42193\n","Epoch 28/100\n","1038/1038 [==============================] - 266s 256ms/step - loss: 0.3860 - val_loss: 0.4419\n","\n","Epoch 00028: val_loss did not improve from 0.42193\n","Epoch 29/100\n","1038/1038 [==============================] - 261s 252ms/step - loss: 0.3835 - val_loss: 0.4132\n","\n","Epoch 00029: val_loss improved from 0.42193 to 0.41317, saving model to /content/drive/My Drive/MELD-master/data/models/text_weights_emotion.hdf5\n","Epoch 30/100\n","1038/1038 [==============================] - 266s 256ms/step - loss: 0.3792 - val_loss: 0.4670\n","\n","Epoch 00030: val_loss did not improve from 0.41317\n","Epoch 31/100\n","1038/1038 [==============================] - 261s 252ms/step - loss: 0.3790 - val_loss: 0.4159\n","\n","Epoch 00031: val_loss did not improve from 0.41317\n","Epoch 32/100\n","1038/1038 [==============================] - 262s 252ms/step - loss: 0.3770 - val_loss: 0.4103\n","\n","Epoch 00032: val_loss improved from 0.41317 to 0.41029, saving model to /content/drive/My Drive/MELD-master/data/models/text_weights_emotion.hdf5\n","Epoch 33/100\n","1038/1038 [==============================] - 266s 256ms/step - loss: 0.3747 - val_loss: 0.4086\n","\n","Epoch 00033: val_loss improved from 0.41029 to 0.40859, saving model to /content/drive/My Drive/MELD-master/data/models/text_weights_emotion.hdf5\n","Epoch 34/100\n","1038/1038 [==============================] - 262s 252ms/step - loss: 0.3718 - val_loss: 0.4122\n","\n","Epoch 00034: val_loss did not improve from 0.40859\n","Epoch 35/100\n","1038/1038 [==============================] - 265s 255ms/step - loss: 0.3709 - val_loss: 0.4191\n","\n","Epoch 00035: val_loss did not improve from 0.40859\n","Epoch 36/100\n","1038/1038 [==============================] - 261s 252ms/step - loss: 0.3705 - val_loss: 0.4108\n","\n","Epoch 00036: val_loss did not improve from 0.40859\n","Epoch 37/100\n","1038/1038 [==============================] - 264s 254ms/step - loss: 0.3659 - val_loss: 0.4067\n","\n","Epoch 00037: val_loss improved from 0.40859 to 0.40665, saving model to /content/drive/My Drive/MELD-master/data/models/text_weights_emotion.hdf5\n","Epoch 38/100\n","1038/1038 [==============================] - 261s 251ms/step - loss: 0.3624 - val_loss: 0.4015\n","\n","Epoch 00038: val_loss improved from 0.40665 to 0.40152, saving model to /content/drive/My Drive/MELD-master/data/models/text_weights_emotion.hdf5\n","Epoch 39/100\n","1038/1038 [==============================] - 261s 252ms/step - loss: 0.3637 - val_loss: 0.4511\n","\n","Epoch 00039: val_loss did not improve from 0.40152\n","Epoch 40/100\n","1038/1038 [==============================] - 264s 255ms/step - loss: 0.3595 - val_loss: 0.4052\n","\n","Epoch 00040: val_loss did not improve from 0.40152\n","Epoch 41/100\n","1038/1038 [==============================] - 261s 251ms/step - loss: 0.3577 - val_loss: 0.4055\n","\n","Epoch 00041: val_loss did not improve from 0.40152\n","Epoch 42/100\n","1038/1038 [==============================] - 265s 255ms/step - loss: 0.3532 - val_loss: 0.4147\n","\n","Epoch 00042: val_loss did not improve from 0.40152\n","Epoch 43/100\n","1038/1038 [==============================] - 263s 253ms/step - loss: 0.3477 - val_loss: 0.4402\n","\n","Epoch 00043: val_loss did not improve from 0.40152\n","Epoch 44/100\n","1038/1038 [==============================] - 265s 256ms/step - loss: 0.3521 - val_loss: 0.3904\n","\n","Epoch 00044: val_loss improved from 0.40152 to 0.39040, saving model to /content/drive/My Drive/MELD-master/data/models/text_weights_emotion.hdf5\n","Epoch 45/100\n","1038/1038 [==============================] - 261s 251ms/step - loss: 0.3455 - val_loss: 0.4008\n","\n","Epoch 00045: val_loss did not improve from 0.39040\n","Epoch 46/100\n","1038/1038 [==============================] - 260s 251ms/step - loss: 0.3403 - val_loss: 0.4038\n","\n","Epoch 00046: val_loss did not improve from 0.39040\n","Epoch 47/100\n","1038/1038 [==============================] - 265s 255ms/step - loss: 0.3502 - val_loss: 0.4248\n","\n","Epoch 00047: val_loss did not improve from 0.39040\n","Epoch 48/100\n","1038/1038 [==============================] - 261s 252ms/step - loss: 0.3330 - val_loss: 0.4125\n","\n","Epoch 00048: val_loss did not improve from 0.39040\n","Epoch 49/100\n","1038/1038 [==============================] - 265s 255ms/step - loss: 0.3375 - val_loss: 0.4455\n","\n","Epoch 00049: val_loss did not improve from 0.39040\n","Epoch 50/100\n","1038/1038 [==============================] - 261s 251ms/step - loss: 0.3282 - val_loss: 0.3944\n","\n","Epoch 00050: val_loss did not improve from 0.39040\n","Epoch 51/100\n","1038/1038 [==============================] - 265s 255ms/step - loss: 0.3284 - val_loss: 0.3837\n","\n","Epoch 00051: val_loss improved from 0.39040 to 0.38365, saving model to /content/drive/My Drive/MELD-master/data/models/text_weights_emotion.hdf5\n","Epoch 52/100\n","1038/1038 [==============================] - 261s 252ms/step - loss: 0.3227 - val_loss: 0.3861\n","\n","Epoch 00052: val_loss did not improve from 0.38365\n","Epoch 53/100\n","1038/1038 [==============================] - 261s 251ms/step - loss: 0.3121 - val_loss: 0.4526\n","\n","Epoch 00053: val_loss did not improve from 0.38365\n","Epoch 54/100\n","1038/1038 [==============================] - 265s 255ms/step - loss: 0.3213 - val_loss: 0.3922\n","\n","Epoch 00054: val_loss did not improve from 0.38365\n","Epoch 55/100\n","1038/1038 [==============================] - 261s 251ms/step - loss: 0.3183 - val_loss: 0.3838\n","\n","Epoch 00055: val_loss did not improve from 0.38365\n","Epoch 56/100\n","1038/1038 [==============================] - 264s 254ms/step - loss: 0.3130 - val_loss: 0.3986\n","\n","Epoch 00056: val_loss did not improve from 0.38365\n","Epoch 57/100\n","1038/1038 [==============================] - 261s 251ms/step - loss: 0.3011 - val_loss: 0.4172\n","\n","Epoch 00057: val_loss did not improve from 0.38365\n","Epoch 58/100\n","1038/1038 [==============================] - 264s 255ms/step - loss: 0.3166 - val_loss: 0.3910\n","\n","Epoch 00058: val_loss did not improve from 0.38365\n","Epoch 59/100\n","1038/1038 [==============================] - 261s 251ms/step - loss: 0.2990 - val_loss: 0.3856\n","\n","Epoch 00059: val_loss did not improve from 0.38365\n","Epoch 60/100\n","1038/1038 [==============================] - 261s 251ms/step - loss: 0.2969 - val_loss: 0.4007\n","\n","Epoch 00060: val_loss did not improve from 0.38365\n","Epoch 61/100\n","1038/1038 [==============================] - 264s 254ms/step - loss: 0.2904 - val_loss: 0.4253\n","\n","Epoch 00061: val_loss did not improve from 0.38365\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:162: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ut...)`\n"],"name":"stderr"},{"output_type":"stream","text":["Confusion Matrix :\n","[[1129   48    0   13   56    0   10]\n"," [  75  141    0    1   52    0   12]\n"," [  28    5    0    0    9    0    8]\n"," [ 141    9    0   14   23    0   21]\n"," [ 143   33    0    5  203    0   18]\n"," [  42    9    0    4    3    0   10]\n"," [ 126   59    0   10   75    0   75]]\n","Classification Report :\n","              precision    recall  f1-score   support\n","\n","           0     0.6704    0.8989    0.7680      1256\n","           1     0.4638    0.5018    0.4821       281\n","           2     0.0000    0.0000    0.0000        50\n","           3     0.2979    0.0673    0.1098       208\n","           4     0.4822    0.5050    0.4933       402\n","           5     0.0000    0.0000    0.0000        68\n","           6     0.4870    0.2174    0.3006       345\n","\n","    accuracy                         0.5985      2610\n","   macro avg     0.3430    0.3129    0.3077      2610\n","weighted avg     0.5349    0.5985    0.5460      2610\n","\n","Weighted FScore: \n","  (0.5349443107685684, 0.5984674329501916, 0.5459611896110692, None)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"0Aw7aG9dANht","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":523},"executionInfo":{"status":"ok","timestamp":1593886242306,"user_tz":-330,"elapsed":184809,"user":{"displayName":"Ashutosh Jindal","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gh5QBA10uYxcnUyu5IeQy9b1yLimJ-Fm5utDrv3=s64","userId":"00737864440241259346"}},"outputId":"11d23c06-f6a4-44aa-a263-300295162118"},"source":["model.test_model()"],"execution_count":8,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:162: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ut...)`\n"],"name":"stderr"},{"output_type":"stream","text":["Confusion Matrix :\n","[[1129   48    0   13   56    0   10]\n"," [  75  141    0    1   52    0   12]\n"," [  28    5    0    0    9    0    8]\n"," [ 141    9    0   14   23    0   21]\n"," [ 143   33    0    5  203    0   18]\n"," [  42    9    0    4    3    0   10]\n"," [ 126   59    0   10   75    0   75]]\n","Classification Report :\n","              precision    recall  f1-score   support\n","\n","           0     0.6704    0.8989    0.7680      1256\n","           1     0.4638    0.5018    0.4821       281\n","           2     0.0000    0.0000    0.0000        50\n","           3     0.2979    0.0673    0.1098       208\n","           4     0.4822    0.5050    0.4933       402\n","           5     0.0000    0.0000    0.0000        68\n","           6     0.4870    0.2174    0.3006       345\n","\n","    accuracy                         0.5985      2610\n","   macro avg     0.3430    0.3129    0.3077      2610\n","weighted avg     0.5349    0.5985    0.5460      2610\n","\n","Weighted FScore: \n","  (0.5349443107685684, 0.5984674329501916, 0.5459611896110692, None)\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"],"name":"stderr"}]}]}